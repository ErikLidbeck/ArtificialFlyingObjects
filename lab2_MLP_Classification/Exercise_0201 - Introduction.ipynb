{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:40px;\">Exercise II:<br> Multi-layer perceptrons\n",
    "for classification and regression problems.\n",
    "</h1></center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second lab in the Deep learning course! In this lab we will continue to take a look at four parts for MLP classification;\n",
    "* Introduction for setup and train an MLP\n",
    "* Impact of overfitting in validation performance \n",
    "* Avoid overfitting for a regression problem\n",
    "* Model selection for classification\n",
    "\n",
    "\n",
    "\n",
    "The lab includes different datasets, binary and multiple classification problems, and function approximation problems. \n",
    "The first part of the lab uses three different synthetic classification problems. They are all 2D binary classification problems that allow for easy visual inspection of the other classes and the network decision boundary. The datasets are defined as *syn1, syn2*, and *syn3*. These datasets are generated \"on the fly\" each time and are sampled from normal distributions. Note that as the data is sampled from a distribution, the data will vary for each time the data is generated it will be slightly different.\n",
    "\n",
    "All tasks include **TODO's** these are expected to be done before the deadline for this lab. The labs also include **Question**, which should be answered and included in the report. The lab gives a hand to ensure correct answer with a few asserts or the expected results. Some sections do not contain any **TODO's** but are good to understand.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows us to edit imported files without restarting the kernel for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Hacky solution to access the global utils package\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3541817/3495477086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from config import LabConfig\n",
    "from dataset import MLPData\n",
    "from utils.model import Model\n",
    "from utils.progressbar import LitProgressBar\n",
    "from utils.model import Model\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import (\n",
    "    plot,\n",
    "    progressbar\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = LabConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data\n",
    "To get an idea of the datasets for this lab. Below plots with 100 sample points are generated for syn1-syn3 and the spiral dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.data_distribution({\n",
    "    \"Syn1\":MLPData.syn1(100),\n",
    "    \"Syn2\":MLPData.syn2(100),\n",
    "    \"Syn3\":MLPData.syn3(100),\n",
    "    \"Spiral\":MLPData.spiral(cfg.spiral_path)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the MLP model\n",
    "\n",
    "This cell defines the MLP model. There are a number of parameters that is needed to \n",
    "define a model. Here is a list of them: **Note:** They can all be specified when you call\n",
    "this function in later cells. The ones specified in this cell are the default values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                inp_dim=None,         \n",
    "                hidden_nodes=1,                      # number of nodes in hidden layer\n",
    "                num_out=None,\n",
    "                **kwargs\n",
    "            ):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(inp_dim, hidden_nodes)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_nodes, num_out)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(relu)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function that allow us to convert numpy to pytorch DataLoader\n",
    "With this fucnction we can take a dataset from numpy and convert it to a torch tensor and then to a Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2Dataloader(x,y, batch_size=25, num_workers=10,**kwargs):\n",
    "    return DataLoader(\n",
    "        TensorDataset(\n",
    "            torch.from_numpy(x).float(), \n",
    "            torch.from_numpy(y).unsqueeze(1).float()\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1\n",
    "The cell below should be used for question 1. Looking at the code will help you understand how the network is created, trained and evaluated. It will be useful for the other questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Use syn1 with 100 data points and train a linear MLP to separate the two classes, i.e. use a single hidden node. What happened? Can the problem be solved with a single hidden node?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we convert our dataset into a pytorch Dataset. Thereafter we load it into our DataLoader. Note that we here define the batch_size and the number of workers that should be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = MLPData.syn1(10000)\n",
    "train_loader = numpy2Dataloader(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Setup our local config that should be used for the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'max_epochs':4,\n",
    "    'model_params':{\n",
    "        'inp_dim':x.shape[1],         \n",
    "        'hidden_nodes':1,   # activation functions for the hidden layer\n",
    "        'num_out':1 # if binary --> 1 |  regression--> num inputs | multi-class--> num of classes\n",
    "    },\n",
    "    'criterion':torch.nn.BCELoss(), # error function\n",
    "    'optimizer':{\n",
    "        \"type\":torch.optim.Adam,\n",
    "        \"args\":{\n",
    "            \"lr\":0.005,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, put everything together and call on the trainers fit method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(MLP(**config[\"model_params\"]),**config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "            max_epochs=config['max_epochs'], \n",
    "            gpus=cfg.GPU,\n",
    "            logger=pl.loggers.TensorBoardLogger(save_dir=cfg.TENSORBORD_DIR),\n",
    "            callbacks=[LitProgressBar()],\n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10,   \n",
    "        )\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_dataloader=train_loader\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.decision_bondary(trainer.lightning_module, x,y) # To be fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.stats_class()\n",
    "plot.stats_class(x, y, 'Training', trainer.get_model())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ccf88e37874d44b4dfe33c31e1bb4a10ca4e414e0a68744582aebd290f71bcd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
