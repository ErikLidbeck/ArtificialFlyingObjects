{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><center>Exercise III: Regression\n",
    "    \n",
    "</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to look at a regression problem. The data as described above (regr1) consists of 6 inputs (features) and one output (target) value. As for previous examples a new data set is generated each time you call the *regr1* function. To get exactly the same data set between different calls, use a fixed seed. New for this problem is that one can also control the amount of noise added to the target value. We are going to use a relatively small training dataset (~250) and a larger validation dataset (~1000) to get a more robust estimation of the generalization performance. For regression problems we also need new performance measures. The *stats_reg* function will give you two such measures:\n",
    "* MSE = mean squared error (low error mean good performance)\n",
    "* CorrCoeff = Pearson correlation coefficient for the scatter plot between predicted and true values.\n",
    "\n",
    "The cell below can be used as an template for all questions regarding this regression problem.\n",
    "\n",
    "# Data \n",
    "## regr1\n",
    "There is also a synthetic regression problem, called *regr1*. It has 6 inputs (independent variables) and one output variable (dependent variable). It is generated according to the following formula:  \n",
    "\n",
    "$\\qquad d = 2x_1 + x_2x_3^2 + e^{x_4} + 5x_5x_6 + 3\\sin(2\\pi x_6) + \\alpha\\epsilon$  \n",
    "    \n",
    "where $\\epsilon$ is added normally distributed noise and $\\alpha$ is a parameter controlling the size of the added noise. Variables $x_1,...,x_4$ are normally distrubuted with zero mean and unit variance, whereas $x_5, x_6$ are uniformly distributed ($[0,1]$). The target value $d$ has a non-linear dependence on ***x***.\n",
    "\n",
    "\n",
    "# Tasks\n",
    "\n",
    "## Task 1\n",
    "Use 250 data points for training and about 1000 for validation and **no** added noise. Train an MLP to predict the target output. If you increase the complexity of the model (e.g. number of hidden nodes) you should be able to reach a very small training error. You will also most likely see that the validation error decreases as you increase the complexity or at least no clear sign of overtraining. \n",
    "\n",
    "**Note:** As with previous examples you may need to tune the optimization parameters to make sure that you have \"optimal\" training. That is, increase or decrease the learningrate, possibly train longer times (increase *epochs*) and change the *batch_size* parameter.\n",
    "\n",
    "**Question:** Even though the validation error is most likely still larger than the training error why do we not see any overtraining of the model? (Hint: What is it that typically causes overfitting?)\n",
    "\n",
    "## Task 2\n",
    "Use the same training and validation data sets as above, but add 0.4 units of noise (set the second parameter when calling the *regr1* function to 0.4 for both training and validation). Now train again, starting with a \"small\" model and increase the number of hidden nodes as you monitor the validation result for each model. Make a note of the validation error you obtained a this point!\n",
    "\n",
    "**Question:** How many nodes do you have for opitimal validation performance, i.e. more hidden nodes results in overtraining?\n",
    "\n",
    "## Task 3\n",
    "Instead of using the number of hidden nodes to control the complexity it is often better to use a regularization term added to the error function. You are now going to control the complexity by adding a *L2* regularizer (see the \"INPUT\" dictionary in the cell). You should modify this value until you find the \"near optimal\" validation performance. Use 15 hidden nodes. \n",
    "\n",
    "**Question:** Give the L2 value that you found to give \"optimal\" validation performance and compare with the result from  question 7 (optimal performance).\n",
    "\n",
    "## Task 4\n",
    "Summarize your findings in a few sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate training and validation data\n",
    "x_train, d_train = MLPData.regr1(250, 0.0) # 250 data points with no noise\n",
    "x_val, d_val = MLPData.regr1(1000, 0.0)\n",
    "\n",
    "# Here we need to normalize the target values\n",
    "norm_m = d_train.mean(axis=0)\n",
    "norm_s = d_train.std(axis=0)\n",
    "d_train = (d_train - norm_m) / norm_s\n",
    "\n",
    "# We use the same normalization for the validation data.\n",
    "d_val = (d_val - norm_m) / norm_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_params':{\n",
    "        'inp_dim':x_train.shape[1],         \n",
    "        'hidden_nodes':1,   # activation functions for the hidden layer\n",
    "        'num_out':1 # if binary --> 1 |  regression--> num inputs | multi-class--> num of classes\n",
    "    },\n",
    "    'optimizer':'Adam',               # minimization method\n",
    "    'criterion':'BCELoss', # error function\n",
    "    'max_epochs':10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 3 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n",
      "Epoch 100 [4/4] {'loss': '0.613'}\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_trn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1c247dfaef09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#pred_trn = model.predict(x_train).reshape(d_train.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#pred_val = model.predict(x_val).reshape(d_val.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_trn' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the model\n",
    "model = Agent(MLP,**config)\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(\n",
    "            max_epochs=config['max_epochs'], \n",
    "            gpus=-1 if torch.cuda.is_available() else None, \n",
    "            logger=metrics.MetricsLogger(),\n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10, \n",
    "            callbacks=[progressbar.LitProgressBar()]\n",
    "        )\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloaders=val_loader\n",
    ");\n",
    "\n",
    "# Call the stats function to print out statistics for classification problems\n",
    "#pred_trn = model.predict(x_train).reshape(d_train.shape)\n",
    "#pred_val = model.predict(x_val).reshape(d_val.shape)\n",
    "plot.stats_reg(d_train, pred_trn, 'Training', estimator)\n",
    "plot.stats_reg(d_val, pred_val, 'Validation', estimator)\n",
    "\n",
    "# Scatter plots of predicted and true values\n",
    "plt.figure()\n",
    "plt.plot(d_train, pred_trn, 'g*', label='Predict vs True (Training)')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(d_val, pred_val, 'b*', label='Predict vs True (Validation)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure()\n",
    "plt.plot(estimator.history['loss'], label='Training')\n",
    "plt.plot(estimator.history['val_loss'], label='Validation')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-Labs",
   "language": "python",
   "name": "dl-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
