{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:40px;\">Exercise II: Classification</h1></center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise you are given two classification problems with a fixed training-, validation- and test dataset. A spiral dataset and a japanese vowels dataset.\n",
    "\n",
    "The **task** is to do model selection, coming up with your optimal MLP architecture together with the hyperparameters. For this part no code for the configuration or training are given. Please implement this based on the previous parts. A small evaluation section is provided to observe the confusion matrix for the prediction vs target.\n",
    "\n",
    "# Data\n",
    "## Japanese vowels dataset\n",
    "This data set is taken from the UCI Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels]. In short, nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, a discrete times series was produced where each time point consists of 12 (LPC cepstrum) coefficients. The length of each time series was between 7-29. \n",
    "Here we treat each point of the time series as a feature (12 inputs). In total we have 9961\n",
    "data points which then has been divided into 4274 for training, 2275 for validation and 3412 for test. The original data files are provided as *ae.train* and *ae.test*. The task is now based on a single sample value of one of the speakers, determine which speaker it was. This is, in summary, a 9-class classification problem with 12 input values for each case.\n",
    "\n",
    "## Spiral data\n",
    "This is the \"famous\" spiral dataset that consists of two 2-D spirals, one for each class. The perfect classification boundary is also a spiral. The cell \"PlotData\" will plot this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows us to edit imported files without restarting the kernel for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Hacky solution to access the global utils package\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from config import LabConfig\n",
    "from dataset import MLPData\n",
    "from utils.model import Model\n",
    "from utils.progressbar import LitProgressBar\n",
    "from utils.model import Model\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchmetrics\n",
    "from utils import (\n",
    "    plot,\n",
    "    progressbar\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = LabConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "**TODO:** Present an MLP for the Japanese vowels dataset with associated hyperparameters that maximizes the validation performance and give the test performance you obtained. \\\n",
    "**TODO:** Motivate the choice of parameters and implementation. \n",
    "\n",
    "**Hint 2:** This problem is a 9-class classification problem, meaning that you should use a specific output activation function (*out_act_fun*) and a specific loss/error function (*cost_fun*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset - Vowels\n",
    "from DL_labs.utils.utils import onehot2int\n",
    "def numpy2Dataloader(x,y, batch_size=25, num_workers=10,**kwargs):\n",
    "    return DataLoader(\n",
    "        TensorDataset(\n",
    "            torch.from_numpy(x).float(), \n",
    "            torch.from_numpy(np.argmax(y,axis=1)).long()\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = MLPData.vowels(file_name_train=cfg.ae_train, file_name_test=cfg.ae_test)\n",
    "\n",
    "train_loader = numpy2Dataloader(x_train,y_train)\n",
    "val_loader =  numpy2Dataloader(x_val,y_val)\n",
    "test_loader =  numpy2Dataloader(x_test,y_test)\n",
    "\n",
    "num_classes = 9\n",
    "print(f'|{\"Type\":10} | {\"Input size\":10} | {\"Target size\":10}|')\n",
    "print(f'|{\"-\"*11}|{\"-\"*12}|{\"-\"*12}|')\n",
    "print(f'|{\"train\":10} | {str(x_train.shape):10} | {str(y_train.shape):10} |')\n",
    "print(f'|{\"val\":8}   | {str(x_val.shape):10} | {str(y_val.shape):10} |')\n",
    "print(f'|{\"test\":9}  | {str(x_test.shape):10} | {str(y_test.shape):10} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Create model \n",
    "\n",
    "# TODO - Setup configurations\n",
    "\n",
    "# TODO - Run model\n",
    "\n",
    "# TODO - Validate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "For this last exercise the task is to train a binary classifier for the spiral problem. The aim is to get *zero* classification error for the training data (there is no test data) with as small as possible model, in terms of the number of trainable weights. Also plot the boundary to see if it resembles a spriral. To pass this question you should at least try!\n",
    "\n",
    "**TODO:** Train a classifier for the spiral problem with the aim of zero classification error with as small as possible model. \n",
    "\n",
    "**TODO:** Motivate the choice of parameters and implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def numpy2Dataloader(x,y, batch_size=25, num_workers=10,**kwargs):\n",
    "    return DataLoader(\n",
    "        TensorDataset(\n",
    "            torch.from_numpy(x).float(), \n",
    "            torch.from_numpy(y).long()\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        **kwargs\n",
    "    )\n",
    "x_train, y_train = MLPData.spiral(cfg.spiral_path)\n",
    "train_loader = numpy2Dataloader(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the TODO's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Create model \n",
    "\n",
    "# TODO - Setup configurations\n",
    "\n",
    "# TODO - Run model\n",
    "\n",
    "# TODO - Validate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of evaluation\n",
    "Run the testset and evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to correct device!\n",
    "trainer.test(model, test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(torch.nn.functional.softmax(model(torch.from_numpy(x_train).float())),dim=1)\n",
    "target = torch.argmax(torch.from_numpy(y_train), axis=1)\n",
    "\n",
    "confuTst = torchmetrics.functional.confusion_matrix(predictions.detach().cpu(),target.int().detach().cpu(), cfg.AE_NUM_CLASSES)\n",
    "\n",
    "plot.confusion_matrix(cm = confuTst.numpy(), \n",
    "                      normalize = False,\n",
    "                      target_names = cfg.AE_CLASSES,\n",
    "                      title = \"Confusion Matrix: Test data\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ccf88e37874d44b4dfe33c31e1bb4a10ca4e414e0a68744582aebd290f71bcd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
