{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:40px;\">Project 2<br> GANs\n",
    "</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Hacky solution to acces the global utils package\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('../..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We first start with importing all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from config import LabConfig\n",
    "\n",
    "cfg = LabConfig()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH),interpolation=torchvision.transforms.InterpolationMode.NEAREST), \n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH),interpolation=torchvision.transforms.InterpolationMode.NEAREST), #, \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Here, we have the network model class definition. In this class, the most important functions are **build_generator()** and **build_discriminator()**. As defined in the exercises section, your task is to update the both network architectures defined in these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 128)\n",
    "        self.fc2 = nn.Linear(128, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 28*28)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        # mixing above 3 steps in single line\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.fc3(x)), 0.2)\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        return x.view(x.shape[0], *img_shape)\n",
    "\n",
    "\n",
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, **hparams):\n",
    "        super(GAN, self).__init__()\n",
    "\n",
    "        self.hparams.update(hparams)\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "    \n",
    "    # Forward Pass of Model\n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    "    \n",
    "    # Loss Function\n",
    "    def loss_function(self, y_hat, y):\n",
    "        return nn.BCELoss()(y_hat, y)\n",
    "    \n",
    "    # Optimizers\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=self.hparams.lr, betas=(0.4, 0.999))\n",
    "        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=self.hparams.lr, betas=(0.4, 0.999))\n",
    "        \n",
    "        # return the list of optimizers and second empty list is for schedulers (if any)\n",
    "        return [optimizer_G, optimizer_D], []\n",
    "    \n",
    "    # Training Loop\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        # batch returns x and y tensors\n",
    "        real_images, _ = batch\n",
    "        \n",
    "        # ground truth (tensors of ones and zeros) same shape as images\n",
    "        valid = torch.ones(real_images.size(0), 1)\n",
    "        fake = torch.zeros(real_images.size(0), 1)\n",
    "        \n",
    "        # svaing loss_function as local variable\n",
    "        criterion = self.loss_function\n",
    "        \n",
    "        # As there are 2 optimizers we have to train for both using 'optimizer_idx'\n",
    "        ## Generator\n",
    "        if optimizer_idx == 0:\n",
    "            # Generating Noise (input for the generator)\n",
    "            gen_input = torch.randn(real_images.shape[0], 100)\n",
    "            \n",
    "            # Converting noise to images\n",
    "            self.gen_images = self.generator(gen_input)\n",
    "            \n",
    "            # Calculating generator loss\n",
    "            # How well the generator can create real images\n",
    "            g_loss = criterion(self(self.gen_images), valid)\n",
    "            \n",
    "            # for output and logging purposes (return as dictionaries)\n",
    "            \n",
    "            self.log('g_loss_train', g_loss)\n",
    "            return g_loss\n",
    "\n",
    "        ## Discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Calculating disciminator loss\n",
    "            # How well discriminator identifies the real and fake images\n",
    "            real_loss = criterion(self(real_images), valid)\n",
    "            fake_loss = criterion(self(self.gen_images.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss)/2.0\n",
    "            \n",
    "            # for output and logging purposes (return as dictionaries)\n",
    "            self.log('d_loss_train',d_loss)\n",
    "            return d_loss\n",
    "    \n",
    "    # calls after every epoch ends\n",
    "    def on_epoch_end(self):\n",
    "        # Saving 5x5 grid\n",
    "        utils.save_image(self.gen_images.data[:25], path+'/%d.png' % self.current_epoch, nrow=5, padding=0, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "No `train_dataloader()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-659bae30a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Fitting the model to trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_validator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify_loop_configurations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# attach model log function to callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py\u001b[0m in \u001b[0;36mverify_loop_configurations\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \"\"\"\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTrainerFn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFITTING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainerFn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__verify_train_loop_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__verify_eval_loop_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrainerFn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py\u001b[0m in \u001b[0;36m__verify_train_loop_configuration\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mhas_train_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_overridden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_dataloader'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_train_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;34m'No `train_dataloader()` method defined. Lightning `Trainer` expects as minimum a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;34m' `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: No `train_dataloader()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined."
     ]
    }
   ],
   "source": [
    "from DL_labs.utils.utils import dict_to_args\n",
    "hparams = dict_to_args({'batch_size': 32,\n",
    "                        'lr': 2e-4,\n",
    "                        'epochs': 20,\n",
    "                        'optimizer':'Adam'\n",
    "                      })\n",
    "\n",
    "gan = GAN(hparams=hparams)\n",
    "\n",
    "# PyTorch Lightning Trainer (where loss backward, optimizer grading, gpu/tpu code automates)\n",
    "trainer = pl.Trainer(max_epochs=hparams.epochs, fast_dev_run=False)\n",
    "\n",
    "# Fitting the model to trainer\n",
    "trainer.fit(gan, datamodule=dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1)\n",
    "Update the network architecture given in  **build_generator**  and  **build_discriminator**  of the class GANModel. Please note that the current image resolution is set to 32x32 (i.e. IMAGE_WIDTH and IMAGE_HEIGHT values) in the file configGAN.py. \n",
    "This way initial experiements can run faster. Once you implement the inital version of the network, please set the resolution values back to 128x128. Experimental results should be provided for this high resolution images.  \n",
    "\n",
    "**Hint:** As a generator model, you can use the segmentation model implemented in lab03. Do not forget to adapt the input and output shapes of the generator model in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2) \n",
    "Use different **optimization** (e.g. ADAM, SGD, etc) and **regularization** (e.g. data augmentation, dropout) methods to increase the network accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
