{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><center>Exercise III:<br> Image Segmentation using CNNs</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what semantic segmentation is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short summary\n",
    "In this exercise, we will design a CNN-based **encoder-decoder architecture** to segment rgb images. Image segmentation refers to dividing the image into semantically meaningful regions. For instance, representing each object in the scene with a unique color. The current folder has **three files**: \n",
    "- **configSegmenter.py:** this involves definitions of all parameters and data paths\n",
    "- **utilsSegmenter.py:** includes utility functions required to grab and visualize data \n",
    "- **runSegmenter.ipynb:** contains the script to design, train and test the network \n",
    "\n",
    "Make sure that before running this script, you created an environment and **installed all required libraries** such \n",
    "as keras. The very same environment used in Exercise II can be used here as well.\n",
    "\n",
    "## Data\n",
    "There exists also a subfolder called **data** which contains the traning, validation, and testing data each has both RGB input images together with the corresponding ground truth segmentation images.\n",
    "\n",
    "## Writing the report\n",
    "First the report should be written within this notebook. We have prepared the last cell in this notebook for you where you should write the report. The report should contain 4 parts:\n",
    "\n",
    "* Name:\n",
    "* Introduction: A **few** sentences where you give a small introduction of what you have done in the lab.\n",
    "* Answers to questions: For each of the questions provide an answer. It can be short answers or a longer ones depending on the nature of the questions, but try to be effective in your writing.\n",
    "* Conclusion: Summarize your findings in a few sentences.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Hacky solution to ac>cess the global utils package\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/f/fremar16/miniconda3/envs/DL-Labs/lib/python3.9/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "# Torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# local modules\n",
    "from torch.utils.data import DataLoader\n",
    "from DL_labs.utils.dataset import SegmentationDataset\n",
    "from DL_labs.utils import dataloader\n",
    "from DL_labs.utils.model import Model\n",
    "from config import flying_objects_config\n",
    "from collections import OrderedDict\n",
    "import torchvision\n",
    "from DL_labs.utils import plot, utils\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config\n",
    "Note that this lab does not support for fineGrained dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLASSES': ['square', 'triangle', 'circular', 'background'],\n",
       " 'fineGrained': False,\n",
       " 'NUM_CLASSES': 4,\n",
       " 'training_img_dir': '../data/FlyingObjectDataset_10K/training',\n",
       " 'validation_img_dir': '../data/FlyingObjectDataset_10K/validation',\n",
       " 'testing_img_dir': '../data/FlyingObjectDataset_10K/testing',\n",
       " 'GPU': -1,\n",
       " 'IMAGE_WIDTH': 128,\n",
       " 'IMAGE_HEIGHT': 128,\n",
       " 'IMAGE_CHANNEL': 3,\n",
       " 'NUM_WORKERS': 4,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'SAVE_EVERY': 1,\n",
       " 'TENSORBORD_DIR': 'logs/'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = flying_objects_config(False)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Task\n",
    "Here is an example of how the network can be setup to train a network to learn semantic segmentation of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "First load the dataloaders for three datasets; train, validation and test. Feel free to test different augmentations, more can be found at *https://pytorch.org/vision/stable/transforms.html*\n",
    "\n",
    "Note that ToTensor and Rezise are required to reshape and transform the images correct. We do not want to apply augmentation to the test_transform that are applied on the validation and test dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmentation\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)), #, interpolation=torchvision.transforms.InterpolationMode.NEAREST\n",
    "    #torchvision.transforms.Lambda(lambda x: utils.normalize(x))\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)), #, interpolation=torchvision.transforms.InterpolationMode.NEAREST\n",
    "    #torchvision.transforms.Lambda(lambda x: utils.normalize(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch generators are created!\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(SegmentationDataset(cfg.training_img_dir, img_shape=(cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), transform=train_transform),\n",
    "                        batch_size=cfg.BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        num_workers=cfg.NUM_WORKERS)\n",
    "valid_dataloader = DataLoader(SegmentationDataset(cfg.validation_img_dir, img_shape=(cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), transform=test_transform),\n",
    "                        batch_size=cfg.BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=cfg.NUM_WORKERS)\n",
    "test_dataloader = DataLoader(SegmentationDataset(cfg.testing_img_dir, img_shape=(cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), transform=test_transform),\n",
    "                        batch_size=cfg.BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=cfg.NUM_WORKERS)\n",
    "\n",
    "predict_dataloader = DataLoader(SegmentationDataset(cfg.testing_img_dir, img_shape=(cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), predict=True, transform=test_transform),\n",
    "                        batch_size=cfg.BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=cfg.NUM_WORKERS)\n",
    "print(\"Data batch generators are created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x, t_y = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (32, 4, 128, 128) torch.float32 0.0 1.0\n",
      "y (32, 128, 128) torch.int64 0 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_x, t_y = next(data)\n",
    "print(f\"x {tuple(t_x.shape)} {t_x.dtype} {t_x.min()} {t_x.max()}\")\n",
    "print(f\"y {tuple(t_y.shape)} {t_y.dtype} {t_y.min()} {t_y.max()}\")\n",
    "plot.Segmentation.data(t_x[:,:3], t_y) #t_x.permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Change to true to see statistics\n",
    "    plot.show_statistics(cfg.training_img_dir, fineGrained=cfg.fineGrained, title=\" Training Data Statistics \")\n",
    "    plot.show_statistics(cfg.validation_img_dir, fineGrained=cfg.fineGrained, title=\" Validation Data Statistics \")\n",
    "    plot.show_statistics(cfg.testing_img_dir, fineGrained=cfg.fineGrained, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 32,\n",
      " 'CLASSES': ['square', 'triangle', 'circular', 'background'],\n",
      " 'GPU': -1,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'NUM_CLASSES': 4,\n",
      " 'NUM_WORKERS': 4,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'TENSORBORD_DIR': 'logs/',\n",
      " 'fineGrained': False,\n",
      " 'testing_img_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_img_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_img_dir': '../data/FlyingObjectDataset_10K/validation'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self,num_classes:int=3, input_shape=(10,10),**kwargs):\n",
    "        super().__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Conv2d(num_classes, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16, num_classes, kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "# Train model\n",
    "config = {\n",
    "    'optimizer':{\n",
    "        \"type\":torch.optim.Adam,\n",
    "        \"args\":{\n",
    "            \"lr\":0.005,\n",
    "        }\n",
    "    },\n",
    "    'criterion':torch.nn.CrossEntropyLoss(), # error function\n",
    "    'max_epochs':59,\n",
    "    \"train_metrics\":torchmetrics.MetricCollection([\n",
    "        torchmetrics.Accuracy(num_classes=cfg.NUM_CLASSES,compute_on_step=False),\n",
    "        torchmetrics.IoU(num_classes=cfg.NUM_CLASSES, compute_on_step=False)\n",
    "    ],postfix=\"_Train\"),\n",
    "    \"validation_metrics\":torchmetrics.MetricCollection([\n",
    "        torchmetrics.Accuracy(num_classes=cfg.NUM_CLASSES,compute_on_step=False),\n",
    "        torchmetrics.IoU(num_classes=cfg.NUM_CLASSES, compute_on_step=False)\n",
    "    ],postfix=\"_Validation\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/stud/f/fremar16/miniconda3/envs/DL-Labs/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 [25/339] {'loss': '0.0172'}}\r"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from DL_labs.utils.progressbar import LitProgressBar\n",
    "#\n",
    "# Load model  cfg.NUM_CLASSES\n",
    "modelObj = Model(SimpleModel(num_classes=cfg.NUM_CLASSES, input_shape=(cfg.IMAGE_CHANNEL, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)),**config)\n",
    "\n",
    "# Setup trainer\n",
    "trainer = pl.Trainer(\n",
    "            max_epochs=config['max_epochs'], \n",
    "            gpus=cfg.GPU,\n",
    "            logger=pl.loggers.TensorBoardLogger(save_dir=cfg.TENSORBORD_DIR),\n",
    "            callbacks=[LitProgressBar()],\n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10,   \n",
    "        )\n",
    "# Train with the training and validation data- \n",
    "trainer.fit(\n",
    "    modelObj, \n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterable from the test dataset\n",
    "iter_dataloader = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one batch from the test dataset and predict!\n",
    "t_data, t_segments = next(iter_dataloader)\n",
    "#pred_segments = model.predict(model, batch_size=cfg.BATCH_SIZE)\n",
    "pred_segments = torch.argmax(modelObj.predict_step(t_data,0,0),dim=1)\n",
    "\n",
    "plot.segmentation_results(t_data[:,:3], t_segments, pred_segments, cfg.NUM_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "### Task 2\n",
    "Even if hyperparameter tuning is an simple approach to improve the performance it might not be enough. Try to modify the architecture of the SimpleModel to further increase the performance. Remember that very deep network allow the network to learn many features but if the dataset is to small the model will underfit. A simple dataset should not require a very deep network to learn good features.\n",
    "\n",
    "**TODO:** Modify the SimpleModel architecture. Force the network to overfit. How bad performance can you get from the network?\n",
    "\n",
    "**TODO:** Modify the SimpleModel and increase the complexity a little. Does the performance improve? If not, did you modify it to much or to little?\n",
    "\n",
    "**TODO:** Modify the SimpleModel architecture. Now combine the hyperparameter tuning and modification of the architecture to reach a performance that is close to the truth images. Explain in detail why the change was applied and if it improved the model a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "### Task 1\n",
    "From the example approach we can see that the network performed very poor. For the network to be consider \"good\" the truth images should match the predicted images. The first task is to tune the parameters of the network. This mostly involves changing the learning rate, optimizers, loss function etc. to better learn features. A network that have a to high learning rate create a increase in variance of the network weights which can make the network unstable.\n",
    "\n",
    "\n",
    "**TODO:** Perform hyperparameter tuning. Explain in detail why the parameters was changed and why it is considered \"better\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "Test if data augmentation help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not sure how to apply augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-Labs",
   "language": "python",
   "name": "dl-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
